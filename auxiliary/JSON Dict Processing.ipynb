{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2258d2d0",
   "metadata": {},
   "source": [
    "# Kindle VocabMate JSON字典產生器\n",
    "\n",
    "## 小学館 大辞泉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import bs4\n",
    "from pyglossary import Glossary\n",
    "\n",
    "def parse_definition(text):\n",
    "    result_texts = []\n",
    "    objSoup = bs4.BeautifulSoup(text, 'lxml')\n",
    "    tag_head = objSoup.find('span', '見出G')\n",
    "    if tag_head:\n",
    "        result_texts.append(f\"<p>{tag_head.text}</p>\")\n",
    "    tag_meaning_list = objSoup.find_all('meaning')\n",
    "    for meaning in tag_meaning_list:\n",
    "        result_texts.append(f\"<p>{meaning.text}</p>\")\n",
    "    return \"\\n\".join(result_texts)\n",
    "\n",
    "\n",
    "\n",
    "Glossary.init()\n",
    "glos = Glossary()\n",
    "\n",
    "with open('Daijisen/outdjs', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        eqv_word = []\n",
    "        ss = line.strip().split('\\t')\n",
    "        word = ss[0]\n",
    "        if \"|\" in ss[0]:\n",
    "            ss2 = ss[0].split('|')\n",
    "            word = ss2[0]\n",
    "        if '【' in word:\n",
    "            m = re.search(r'(.*)【(.*)】', word)\n",
    "            word = m.group(1)\n",
    "            eqv_word.append(word)\n",
    "            hanjis = m.group(2)\n",
    "            if '┊' in hanjis:\n",
    "                ss_hanjis = hanjis.split('┊')\n",
    "                eqv_word.extend(ss_hanjis)\n",
    "            else:\n",
    "                eqv_word.append(hanjis)\n",
    "        else:\n",
    "            eqv_word.append(word)\n",
    "            \n",
    "        final_eqv_word = []\n",
    "        for word in eqv_word:\n",
    "            if '（' in word:\n",
    "                remove_para = word.replace('（', '').replace('）', '')\n",
    "                remove_inner = re.sub(r'（.*?）', '', word)\n",
    "                final_eqv_word.append(remove_para)\n",
    "                final_eqv_word.append(remove_inner)\n",
    "            else:\n",
    "                final_eqv_word.append(word)\n",
    "                \n",
    "        defi = ss[1]\n",
    "        if not final_eqv_word[0].startswith('#'):\n",
    "            defi = parse_definition(defi)\n",
    "        glos.addEntryObj(glos.newEntry(\n",
    "            final_eqv_word,\n",
    "            defi,\n",
    "            defiFormat=\"h\",  # \"m\" for plain text, \"h\" for HTML\n",
    "        ))\n",
    "\n",
    "glos.setInfo(\"title\", \"大辞泉\")\n",
    "glos.setInfo(\"author\", \"松村明\")\n",
    "glos.write(\"test/daijisen.json\", format=\"Json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobj = None\n",
    "with open('test/daijisen.json', 'r', encoding='utf-8') as f:\n",
    "    jobj = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_dict = {}\n",
    "defi_dict = {}\n",
    "defi_id = 1\n",
    "\n",
    "for key in jobj:\n",
    "    eqv_word = []\n",
    "    \n",
    "    if \"|\" in key:\n",
    "        eqv_word = key.split('|')\n",
    "    else:\n",
    "        eqv_word = [key]\n",
    "\n",
    "    defi_dict[str(defi_id)] = jobj[key]\n",
    "    \n",
    "    for word in eqv_word:\n",
    "        if word in word_index_dict:\n",
    "            word_index_dict[word].append(str(defi_id))\n",
    "        else:\n",
    "            word_index_dict[word] = [str(defi_id)]\n",
    "    defi_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test/daijisen.jidx', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(word_index_dict, outf, ensure_ascii=False)\n",
    "with open('test/daijisen.jdict', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(defi_dict, outf, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0042f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "daijisen_ifo = {\n",
    "    \"name\": \"小学館·大辞泉\",\n",
    "    \"lang\": \"ja\",\n",
    "    \"bookname\": \"大辞泉\",\n",
    "    \"author\": \"松村明\",\n",
    "    \"publisher\": \"小学館\",\n",
    "    \"website\": \"\",\n",
    "    \"wordcount\": len(word_index_dict),\n",
    "    \"definitioncount\": len(defi_dict),\n",
    "    \"description\": \"\"\n",
    "}\n",
    "with open('test/daijisen.jifo', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(daijisen_ifo, outf, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd81c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class VocabDictionary():\n",
    "    def __init__(self, name, lang, cover_image):\n",
    "        self.name = name\n",
    "        self.lang = lang\n",
    "        self.cover_image = cover_image\n",
    "        \n",
    "    def query(self, term):\n",
    "        return ''\n",
    "\n",
    "class JsonDictionary(VocabDictionary):\n",
    "    def __init__(self, name, lang, cover_image, file_prefix_path):\n",
    "        super().__init__(name, lang, cover_image)\n",
    "        self.file_prefix_path = file_prefix_path\n",
    "        self.indexes = {}\n",
    "        self.definitions = {}\n",
    "        \n",
    "        self.load_indexes()\n",
    "        self.load_definitions()\n",
    "        \n",
    "    def load_indexes(self):\n",
    "        file_jidx = f\"{self.file_prefix_path}.jidx\"\n",
    "        try:\n",
    "            with open(file_jidx, 'r', encoding='utf-8') as f:\n",
    "                self.indexes = json.load(f)\n",
    "        except:\n",
    "            print(\"Load jidx file Error!\")\n",
    "    \n",
    "    def load_definitions(self):\n",
    "        file_jdict = f\"{self.file_prefix_path}.jdict\"\n",
    "        try:\n",
    "            with open(file_jdict, 'r', encoding='utf-8') as f:\n",
    "                self.definitions = json.load(f)\n",
    "        except:\n",
    "            print(\"Load jdict file Error!\")\n",
    "\n",
    "    def query(self, term):\n",
    "        if term in self.indexes:\n",
    "            word_ids = self.indexes[term]\n",
    "            defis = []\n",
    "            for wid in word_ids:\n",
    "                defis.append(self.definitions[wid])\n",
    "            return \"\\n<br/><br/>\\n\".join(defis)\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c76e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = JsonDictionary('Daijisen', 'ja', 'test.jpg', 'test/daijisen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe94caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1.query('あ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a932ea0",
   "metadata": {},
   "source": [
    "## 三省堂 大辞林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_definition(text):\n",
    "    result_texts = []\n",
    "    objSoup = bs4.BeautifulSoup(text, 'lxml')\n",
    "    tag_hg = objSoup.find('span', 'hg')\n",
    "    hg = tag_hg.text\n",
    "    result_texts.append(f\"<p>{hg}</p>\")\n",
    "    tag_sg_list = objSoup.find_all('span', 'sg')\n",
    "\n",
    "    for tag_sg in tag_sg_list:\n",
    "        tag_posg = tag_sg.find('span', 'posg')\n",
    "        if tag_posg:\n",
    "            pos = tag_posg.text\n",
    "            result_texts.append(f\"<p>{pos}</p>\")\n",
    "\n",
    "        tag_tcord = tag_sg.find_all('span', 't_core')\n",
    "        for tcord in tag_tcord:\n",
    "            result_texts.append(f\"<p>{tcord.text}</p>\")\n",
    "        result_texts.append(\"<br/>\")\n",
    "\n",
    "        tag_tsubsence = tag_sg.find_all('span', 't_large')\n",
    "        for tsubsence in tag_tsubsence:\n",
    "            result_texts.append(f\"<p>{tsubsence.text}</p>\")\n",
    "        if len(tag_tsubsence) > 0:\n",
    "            result_texts.append(\"<br/>\")\n",
    "\n",
    "        tag_infg_list = tag_sg.find_all('span', 'infg')\n",
    "        for tag_infg in tag_infg_list:\n",
    "            tag_lbl = tag_infg.find('span', 'lbl')\n",
    "            tag_inf = tag_infg.find('span', 'inf')\n",
    "            result_texts.append(f\"[{tag_lbl.text}] {tag_inf.text}\")\n",
    "\n",
    "        tag_deri_list = objSoup.find_all('span', 't_derivatives')\n",
    "\n",
    "        for tag_deri in tag_deri_list:\n",
    "            result_texts.append(f\"<p>{tag_deri.text}</p>\")\n",
    "    return \"\\n\".join(result_texts)\n",
    "\n",
    "word_index_dict = {}\n",
    "defi_dict = {}\n",
    "\n",
    "defi_id = 1\n",
    "\n",
    "with open('test/daijirin.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        ss = line.strip().split('\\t')\n",
    "        word = ss[0]\n",
    "        objSoup = bs4.BeautifulSoup(ss[1], 'lxml')\n",
    "        tag_role = objSoup.find('span', {'role':'text'})\n",
    "        if tag_role:\n",
    "            eqv_word = []\n",
    "            if '（' in word:\n",
    "                m = re.search(r'(.*?)（(.*?)）', word)\n",
    "                eqv_word.append(m.group(1))\n",
    "                eqv_word.append(m.group(2))\n",
    "            else:\n",
    "                eqv_word.append(word)\n",
    "            role_text = tag_role.text.replace('・', '').strip()\n",
    "            if role_text != eqv_word[0]:\n",
    "                eqv_word.append(role_text)\n",
    "\n",
    "            defi_dict[str(defi_id)] = parse_definition(ss[1])\n",
    "\n",
    "            for word in eqv_word:\n",
    "                if word in word_index_dict:\n",
    "                    word_index_dict[word].append(str(defi_id))\n",
    "                else:\n",
    "                    word_index_dict[word] = [str(defi_id)]\n",
    "            defi_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32585063",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_index_dict['みちびく'])\n",
    "print(word_index_dict['導く'])\n",
    "print(defi_dict[word_index_dict['導く'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd49680",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test/daijirin.jidx', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(word_index_dict, outf, ensure_ascii=False)\n",
    "with open('test/daijirin.jdict', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(defi_dict, outf, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e092d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "daijirin_ifo = {\n",
    "    \"name\": \"三省堂·スーパー大辞林\",\n",
    "    \"lang\": \"ja\",\n",
    "    \"bookname\": \"スーパー大辞林\",\n",
    "    \"author\": \"松村 明\",\n",
    "    \"publisher\": \"三省堂\",\n",
    "    \"website\": \"\",\n",
    "    \"wordcount\": 409529, #len(word_index_dict),\n",
    "    \"definitioncount\": 265051, #len(defi_dict),\n",
    "    \"description\": \"\"\n",
    "}\n",
    "with open('test/daijirin.jifo', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(daijirin_ifo, outf, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = JsonDictionary('Daijirin', 'ja', 'test.jpg', 'test/daijirin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efadc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict2.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb106855",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict2.definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45e66f",
   "metadata": {},
   "source": [
    "## 譯典通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_definition(text):\n",
    "    result_texts = []\n",
    "    objSoup = bs4.BeautifulSoup(text, 'lxml')\n",
    "    tag_hg = objSoup.find('span', 'hg')\n",
    "    hg = tag_hg.text\n",
    "    result_texts.append(f\"<p>{hg}</p>\")\n",
    "    tag_sg_list = objSoup.find_all('span', 'sg')\n",
    "\n",
    "    for tag_sg in tag_sg_list:\n",
    "        tag_posg = tag_sg.find('span', 'posg')\n",
    "        if tag_posg:\n",
    "            pos = tag_posg.text\n",
    "            result_texts.append(f\"<p>{pos}</p>\")\n",
    "\n",
    "        tag_tcord = tag_sg.find_all('span', 't_core')\n",
    "        for tcord in tag_tcord:\n",
    "            result_texts.append(f\"<p>{tcord.text}</p>\")\n",
    "        result_texts.append(\"<br/>\")\n",
    "\n",
    "        tag_tsubsence = tag_sg.find_all('span', 't_large')\n",
    "        for tsubsence in tag_tsubsence:\n",
    "            result_texts.append(f\"<p>{tsubsence.text}</p>\")\n",
    "        if len(tag_tsubsence) > 0:\n",
    "            result_texts.append(\"<br/>\")\n",
    "\n",
    "        tag_deri_list = objSoup.find_all('span', 't_derivatives')\n",
    "\n",
    "        for tag_deri in tag_deri_list:\n",
    "            result_texts.append(f\"<p>{tag_deri.text}</p>\")\n",
    "    return \"\\n\".join(result_texts)\n",
    "\n",
    "\n",
    "word_index_dict = {}\n",
    "defi_dict = {}\n",
    "\n",
    "defi_id = 1\n",
    "\n",
    "with open('test/dreye.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        ss = line.strip().split('\\t')\n",
    "        word = ss[0]\n",
    "        objSoup = bs4.BeautifulSoup(ss[1], 'lxml')\n",
    "        tag_role = objSoup.find('span', {'role':'text'})\n",
    "        if tag_role:\n",
    "            eqv_word = []\n",
    "            if '（' in word:\n",
    "                m = re.search(r'(.*?)（(.*?)）', word)\n",
    "                eqv_word.append(m.group(1))\n",
    "                eqv_word.append(m.group(2))\n",
    "            else:\n",
    "                eqv_word.append(word)\n",
    "            role_text = tag_role.text.replace('・', '').strip()\n",
    "            if role_text != eqv_word[0]:\n",
    "                eqv_word.append(role_text)\n",
    "\n",
    "            defi_dict[str(defi_id)] = parse_definition(ss[1])\n",
    "\n",
    "            for word in eqv_word:\n",
    "                if word in word_index_dict:\n",
    "                    word_index_dict[word].append(str(defi_id))\n",
    "                else:\n",
    "                    word_index_dict[word] = [str(defi_id)]\n",
    "            defi_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_index_dict['atmosphere'])\n",
    "print(defi_dict[word_index_dict['atmosphere'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a1add",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test/dreye.jidx', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(word_index_dict, outf, ensure_ascii=False)\n",
    "with open('test/dreye.jdict', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(defi_dict, outf, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb83bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dreye_ifo = {\n",
    "    \"name\": \"譯典通英漢雙向辭典\",\n",
    "    \"lang\": \"en\",\n",
    "    \"bookname\": \"譯典通英漢雙向辭典\",\n",
    "    \"author\": \"英業達\",\n",
    "    \"publisher\": \"英業達股份有限公司\",\n",
    "    \"website\": \"\",\n",
    "    \"wordcount\": len(word_index_dict),\n",
    "    \"definitioncount\": len(defi_dict),\n",
    "    \"description\": \"\"\n",
    "}\n",
    "with open('test/dreye.jifo', 'w', encoding='utf-8') as outf:\n",
    "    json.dump(dreye_ifo, outf, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6fccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
